{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Statistical-Learning\" data-toc-modified-id=\"Statistical-Learning-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Statistical Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-is-Statistical-Learning?\" data-toc-modified-id=\"What-is-Statistical-Learning?-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>What is Statistical Learning?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Why-Estimate-$f$?\" data-toc-modified-id=\"Why-Estimate-$f$?-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Why Estimate $f$?</a></span></li><li><span><a href=\"#How-to-Estimate-$f$?\" data-toc-modified-id=\"How-to-Estimate-$f$?-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>How to Estimate $f$?</a></span></li><li><span><a href=\"#Accuracy-vs.-Interpretability\" data-toc-modified-id=\"Accuracy-vs.-Interpretability-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Accuracy vs. Interpretability</a></span></li><li><span><a href=\"#Supervised-vs.-Unsupervised-Learning\" data-toc-modified-id=\"Supervised-vs.-Unsupervised-Learning-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>Supervised vs. Unsupervised Learning</a></span></li><li><span><a href=\"#Regression-vs.-Classification\" data-toc-modified-id=\"Regression-vs.-Classification-2.1.5\"><span class=\"toc-item-num\">2.1.5&nbsp;&nbsp;</span>Regression vs. Classification</a></span></li></ul></li><li><span><a href=\"#Assessing-Model-Accuracy\" data-toc-modified-id=\"Assessing-Model-Accuracy-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Assessing Model Accuracy</a></span><ul class=\"toc-item\"><li><span><a href=\"#Measuring-Quality-of-Fit\" data-toc-modified-id=\"Measuring-Quality-of-Fit-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Measuring Quality of Fit</a></span></li><li><span><a href=\"#The-Bias-Variance-Tradeoff\" data-toc-modified-id=\"The-Bias-Variance-Tradeoff-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>The Bias-Variance Tradeoff</a></span></li><li><span><a href=\"#The-Classification-Setting\" data-toc-modified-id=\"The-Classification-Setting-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>The Classification Setting</a></span></li></ul></li><li><span><a href=\"#Footnotes\" data-toc-modified-id=\"Footnotes-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Footnotes</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Statistical Learning\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Statistical Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given paired data  $(X, Y)$, assume a relationship between $X$ and $Y$ modeled by\n",
    "\n",
    "$$ Y = f(X) + \\epsilon $$\n",
    "\n",
    "where $f:\\mathbb{R}^p \\rightarrow \\mathbb{R}$ is a function and $\\epsilon$ is a random error term with $\\mathbb{E}(\\epsilon) = 0$.\n",
    "\n",
    "***Statistical learning*** is a set of  approaches for estimating $f$<sup><a href='#foot0' id='ref0'>0</a></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Estimate $f$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We may want to ***predict*** the output $Y$ from an estimate $\\hat{f}$ of $f$. The predicted value for a given $Y$ is then $$ \\hat{Y} = \\hat{f}(X)$$. In prediction, we often treat $f$ as a ***black-box***\n",
    "\n",
    "- The mean squared-error<sup><a href='#foot2' id='ref2'>2</a></sup> $\\mathbf{mse}(\\hat{Y})=\\mathbb{E}(Y-\\hat{Y})^2$ is a good measure of the accuracy of $\\hat{Y}$ as a predictor for $Y$.\n",
    "\n",
    "- One can write\n",
    "\n",
    "$$ \\mathbf{mse}(\\hat{Y}) = \\left(f(X) - \\hat{f}(X)\\right)^2 + \\mathbb{V}(\\epsilon) $$\n",
    "\n",
    "These two terms are known as the ***reducible error*** and ***irreducible error***, respectively<sup><a href='#foot3' id='ref3'>3</a></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instead of predicting $Y$ from $X$, we may be more interested how $Y$ changes as a function of $X$. In inference, we usually do not treat $f$ as a black box. \n",
    "\n",
    "Examples of important inference questions:\n",
    "\n",
    "- *Which predictors have the largest influence on the response?*\n",
    "- *What is the relationship between the response and each predictor?*\n",
    "- *Is f linear or non-linear?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Estimate $f$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parametric methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps for parametric method:\n",
    "\n",
    "1. Assume a parametric model for $f$, that is assume a specific functional form<sup><a href='#foot4' id='ref4'>4</a></sup>\n",
    "\n",
    "$$f = f(X, \\boldsymbol{\\beta}) $$\n",
    "\n",
    "for some vector of ***parameters*** $\\boldsymbol{\\beta} = (\\beta_1,\\dots,\\beta_p)^T$  \n",
    "\n",
    "2. Use the training data to ***fit*** or ***train*** the model, that is to choose $\\beta_i$ such that \n",
    "\n",
    "$$Y \\approx f(X, \\boldsymbol{\\beta})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-parametric methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These methods make no assumptions about the functional form of $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy vs. Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In inference, generally speaking the more flexible the method, the less interpretable.\n",
    "\n",
    "- In prediction, generally speaking the more flexible the method, the less accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised vs. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In ***supervised learning***, training data consists of pairs $(X, Y)$ where $X$ is a vector of predictors and $Y$ a response. Prediction and inference are supervised learning problems, and the response variable (or the relationship between the response and the predictors) *supervises* the analysis of model \n",
    "\n",
    "- In ***unsupervised learning***, training data lacks a response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression vs. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Problems with a quantitative response ($Y\\in S \\subseteq \\mathbb{R}$) tend to be called ***regression*** problems\n",
    "\n",
    "- Problems with a qualitative, or categorical response ($Y \\in \\{y_1, \\dots, y_n\\})$ tend to be called ***classification*** problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no free lunch in statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Quality of Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To evaluate the performance of a method on a data set, we need measure model accuracy (how well predictions match observed data). \n",
    "\n",
    "- In regression, the most common measure is the ***mean-squared error***\n",
    "\n",
    "$$MSE = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\hat{f}(x_i))^2$$\n",
    "\n",
    "  where $y_i$ and $\\hat{f}(x_i)$ are the $i$ true and predicting   \n",
    "  responses, respectively.\n",
    "\n",
    "- We are usually not interested in minimizing MSE with respect to training data but rather to test data. \n",
    "\n",
    "- There is no guarantee low training MSE will translate to low test MSE. \n",
    "\n",
    "- Having low training MSE but high test MSE is called ***overfitting***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For a given $x_0$, the expected <sup><a href='#foot5' id='ref5'>5</a></sup> MSE can be written\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb{E}\\left[\\left(y_0 - \\hat{f}(x_0)\\right)^2\\right] \n",
    "&= \\left(\\mathbb{E}\\left[\\hat{f}(x) \\right] - f(x)\\right)^2 + \\mathbb{E}\\left[\\left(\\hat{f}(x_0) - \\mathbb{E}\\left[\\hat{f}(x_0)\\right]\\right)^2\\right] + \\mathbb{E}\\left[\\left(\\epsilon - \\mathbb{E}[\\epsilon]\\right)^2\\right]\\\\\n",
    "&= \\mathbf{bias}^2\\left(\\hat{f}(x_0))\\right) + \\mathbb{V}\\left(\\hat{f}(x_0)\\right) + \\mathbb{V}(\\epsilon)\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "- A good method minimizes variance and bias simultaneously. \n",
    "\n",
    "- As a general rule, these quantities are inversely proportional. More flexible methods have lower bias but higher variance, while less flexible methods have the opposite. This is the ***bias-variance tradeoff*** \n",
    "\n",
    "- In practice the mse, variance and bias cannot be calculated exactly but one must keep the bias-variance tradeoff in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Classification Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the classification setting, the most common measure of model accuracy is the ***error rate*** <sup><a href='#foot6' id='ref6'>6</a></sup>\n",
    "\n",
    "$$\\frac{1}{n}\\sum_{i=1}^n I(y_i \\neq \\hat{y}_i)$$ \n",
    "\n",
    "- As with the regression, we are interested in minimizing the test error rate, not the training error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Given $K$ classes, the ***Bayes Classifier*** predicts\n",
    "\n",
    "$$ \\hat{y_0} = \\underset{1\\leqslant j \\leqslant K}{\\text{argmax}\\,} \\mathbb{P}\\left(Y=j\\ |\\ X = x_0\\right)$$\n",
    "\n",
    "- The set of points \n",
    "$$\\{x_0\\in\\mathbb{R}^p\\ |\\ \\mathbb{P}\\left(Y=j\\ |\\ X = x_0\\right) = \\mathbb{P}\\left(Y=k\\ |\\ X = x_0\\right)\\ \\text{for all}\\ 1\\leqslant j,k \\leqslant K\\}$$\n",
    "\n",
    "    is called the ***Bayes decision boundary***\n",
    "\n",
    "- The test error rate of the Bayes classifier is the ***Bayes error rate***, which is minimal among classifiers. It is given by\n",
    "\n",
    "$$ 1 - \\mathbb{E}\\left(\\underset{j}{\\max} \\mathbb{P}\\left(Y=j\\ |\\ X\\right)\\right)$$\n",
    "\n",
    "- The Bayes classifier is optimal, but in practice we don't know $\\mathbb{P}\\left(Y\\ |\\ X\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The ***K-nearest neighbors*** classifier works by estimating $\\mathbb{P}\\left(Y\\ |\\ X\\right)$ as follows.\n",
    "\n",
    "1. Given $K\\geqslant 1$ and $x_0$,  find the set of points\n",
    "\n",
    "$$ \\mathcal{N}_0 = \\{K\\ \\text{nearest points to}\\ x_0\\}\\subseteq\\mathbb{R}^p $$\n",
    "\n",
    "2. For each class $j$ set \n",
    "\n",
    "$$ \\mathbb{P}\\left(Y=j\\ |\\ X\\right) = \\frac{1}{K}\\sum_{x_i\\in\\mathcal{N}_0}I(y_i = j)$$\n",
    "\n",
    "3. Predict\n",
    "\n",
    "$$ \\hat{y_0} = \\underset{1\\leqslant j \\leqslant K}{\\text{argmax}\\,} \\mathbb{P}\\left(Y=j\\ |\\ X = x_0\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Footnotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "</p>\n",
    "\n",
    "<div id=\"foot0\"> 0. Reading the rest of the chapter, one realized this is the situation for *supervised* learning, which is the vast majority of this book is concerned with. \n",
    "<a href=\"#ref0\">↩</a>\n",
    "</div>\n",
    "\n",
    "<p>\n",
    "</p>\n",
    "\n",
    "<div id=\"foot1\"> 1. Here $X=(X_1,\\dots, X_p)^T$ is a vector.\n",
    "<a href=\"#ref1\">↩</a>\n",
    "</div>\n",
    "\n",
    "<p>\n",
    "</p>\n",
    "\n",
    "<div id=\"foot2\"> 2. This is usual definition of the mean squared-error of $\\hat{Y}$ as an estimator of the (non-parametric) quantity $Y=f(X)$.\n",
    "<a href=\"#ref2\">↩</a>\n",
    "</div>\n",
    "\n",
    "<p>\n",
    "</p>\n",
    "\n",
    "<div id=\"foot3\"> 3. We can in principle control the reducible error by improving the estimate $\\hat{f}$, but we cannot control the irreducible error.\n",
    "<a href=\"#ref3\">↩</a>\n",
    "</div>\n",
    "\n",
    "<p>\n",
    "</p>\n",
    "\n",
    "<div id=\"foot4\"> 4. For example, a simple but popular assumption is that f is linear in both the parameters and the features, that is:\n",
    "    \n",
    "$$f(X) = \\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p$$\n",
    "\n",
    "This is linear regression.\n",
    "<a href=\"#ref4\">↩</a>\n",
    "</div>\n",
    "\n",
    "<p>\n",
    "</p>\n",
    "\n",
    "<div id=\"foot5\"> 5. Here the random variable is $\\hat{f}(x_0)$, so the average is taken over all data sets\n",
    "<a href=\"#ref5\">↩</a>\n",
    "</div>\n",
    "\n",
    "<p>\n",
    "</p>\n",
    "\n",
    "\n",
    "<div id=\"foot6\"> 6. This is just the proportion of misclassified observations.\n",
    "<a href=\"#ref6\">↩</a>\n",
    "</div>\n",
    "\n",
    "<p>\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": "2",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
